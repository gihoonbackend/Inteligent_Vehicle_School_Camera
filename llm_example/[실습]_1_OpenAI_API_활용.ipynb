{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2c4fca33",
      "metadata": {
        "id": "2c4fca33"
      },
      "source": [
        "# Open API 활용해보기\n",
        "\n",
        "\n",
        "OpenAI API를 호출하고 활용할 수 있습니다.   \n",
        "\n",
        "[여기](https://platform.openai.com/account/api-keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caf3f24a",
      "metadata": {
        "id": "caf3f24a"
      },
      "outputs": [],
      "source": [
        "!pip install openai tiktoken --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbf3969a",
      "metadata": {
        "id": "cbf3969a"
      },
      "outputs": [],
      "source": [
        "!pip show openai\n",
        "# 버전 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff9211ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "# key 입력"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7546bc5",
      "metadata": {
        "id": "b7546bc5"
      },
      "source": [
        "\n",
        "사용 가능한 모델의 목록: https://platform.openai.com/docs/models "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0326bb3",
      "metadata": {
        "id": "d0326bb3"
      },
      "source": [
        "openai의 LLM 모델은 현재 다음의 모델 사용이 가능\n",
        "\n",
        "- gpt-4o-mini \n",
        "- gpt-4o \n",
        "- gpt-4-turbo, gpt-4\n",
        "- gpt-3.5-turbo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c100e73",
      "metadata": {
        "id": "7c100e73"
      },
      "source": [
        "  Chat 모델은 채팅 메시지 형태로 데이터를 전달해야 합니다. \n",
        "\n",
        "#### Message의 구성    \n",
        "\n",
        "하나의 채팅 메시지는 `role`과 `content` 조합으로 구성됩니다.   \n",
        "`role`에 따라 system, user, assistant 메시지로 나누어집니다.   \n",
        "\n",
        "시스템 메시지는 GPT의 행동을 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a4e3dfd",
      "metadata": {
        "id": "5a4e3dfd"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {'role':'system', 'content':'you are a helpful assistant.'},\n",
        "    # you are a helpful assistant. : GPT 기본 프롬프트\n",
        "\n",
        "\n",
        "    {'role':'user', 'content':'Gpt는 뭐야?'}\n",
        "    # user message\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f4b4502",
      "metadata": {
        "id": "4f4b4502"
      },
      "source": [
        "메시지 목록을 전달하여, GPT API를 호출합니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c42c39be",
      "metadata": {
        "id": "c42c39be"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages = messages,\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfcb2038",
      "metadata": {
        "id": "dfcb2038"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30709eb7",
      "metadata": {
        "id": "30709eb7"
      },
      "source": [
        "temperature: 무작위 출력을 조절: (0-2) 0에 가까울수록 정해진 답변을 수행\n",
        "max_tokens : 출력 최대 토큰 수 조절: 초과할 경우 자름\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4375172",
      "metadata": {
        "id": "c4375172"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages = messages,\n",
        "    temperature=0.2,\n",
        "    max_tokens = 512,\n",
        "    \n",
        "    # n = 1\n",
        "    # 여러 개의 출력 가능\n",
        "\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09167dc6",
      "metadata": {
        "id": "09167dc6"
      },
      "source": [
        "<br><br><br>\n",
        "### tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d20c84fa",
      "metadata": {
        "id": "d20c84fa"
      },
      "source": [
        "ChatCompletion의 출력 결과를 보면, usage에 토큰 개수가 저장됩니다.   \n",
        "토큰의 개수는 모델이 사용하는 토크나이저마다 다르며,   \n",
        "토큰의 길이는 출력 속도/메모리 사용량/API 요금에 영향을 미칩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29639be0",
      "metadata": {
        "id": "29639be0"
      },
      "source": [
        "tiktoken을 이용하면 모델별 토크나이저를 확인하고, 토큰의 개수를 구할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e1887c7",
      "metadata": {
        "id": "5e1887c7"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo-instruct\")\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fca177d",
      "metadata": {
        "id": "3fca177d"
      },
      "outputs": [],
      "source": [
        "prompt = '지금 이 문장의 글자수와 토큰 수를 구할 수 있습니다.'\n",
        "tokens = tokenizer.encode(prompt)\n",
        "print(tokens)\n",
        "print('총 글자 수:',len(prompt))\n",
        "print('총 토큰 수:',len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d336a5b7",
      "metadata": {
        "id": "d336a5b7"
      },
      "source": [
        "GPT-4o 모델은 개선된 토크나이저를 지원합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94b0d169",
      "metadata": {
        "id": "94b0d169"
      },
      "outputs": [],
      "source": [
        "tokenizer_4o = tiktoken.encoding_for_model(\"gpt-4o\")\n",
        "tokenizer_4o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "794dd41d",
      "metadata": {
        "id": "794dd41d"
      },
      "outputs": [],
      "source": [
        "prompt = '지금 이 문장의 글자수와 토큰 수를 구할 수 있습니다.'\n",
        "\n",
        "# GPT4o : 줄어든 토큰 수\n",
        "\n",
        "tokens= tokenizer_4o.encode(prompt)\n",
        "print(tokens)\n",
        "print('총 글자 수:',len(prompt))\n",
        "print('총 토큰 수:',len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f97ca962",
      "metadata": {
        "id": "f97ca962"
      },
      "source": [
        "\n",
        "LLM은 그 특성상 동일한 input prompt가 들어와도 결과가 항상 다르게 출력되는데,   \n",
        " seed 파라미터는 이를 조절하기 위해 만들어졌습니다.\n",
        "\n",
        "* 출력이 길어지면 결과가 달라집니다.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a742fbea",
      "metadata": {
        "id": "a742fbea"
      },
      "outputs": [],
      "source": [
        "# 프롬프트 준비\n",
        "messages = [\n",
        "    {'role':'system', 'content':'당신은 차량운전자를 위한 비서입니다.'},\n",
        "    {'role':'user', 'content':'지금 너무 추워 어떻게 해?'}\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df465be1",
      "metadata": {
        "id": "df465be1"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages = messages,\n",
        "    temperature =  0.5,\n",
        "    max_tokens = 500,\n",
        "    seed= 8291\n",
        "\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c79b11f9",
      "metadata": {
        "id": "c79b11f9"
      },
      "outputs": [],
      "source": [
        "# 같은 코드로 두 번 실행하기\n",
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages = messages,\n",
        "    temperature =  0.5,\n",
        "    max_tokens = 500,\n",
        "    seed= 8291\n",
        "\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7fac45c",
      "metadata": {
        "id": "c7fac45c"
      },
      "source": [
        "번역, 코딩 등의 작업도 수행할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2f50ce5",
      "metadata": {
        "id": "f2f50ce5"
      },
      "outputs": [],
      "source": [
        "# 번역\n",
        "prompt = '''한국어 문장: 생성형 AI의 능력이 점점 증가하고 있습니다.\n",
        "영어 문장: '''\n",
        "\n",
        "# 프롬프트 준비\n",
        "messages = [\n",
        "    {'role':'user', 'content':prompt}\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eda71634",
      "metadata": {
        "id": "eda71634"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages = messages,\n",
        "    temperature =  0.2,\n",
        "    max_tokens = 500\n",
        "\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77e23ffa",
      "metadata": {
        "id": "77e23ffa"
      },
      "outputs": [],
      "source": [
        "# 코딩\n",
        "prompt = '''# 주어지는 text 문자열에 대해, 공백을 포함한 특수문자를 모두 제거하는 파이썬 코드\n",
        "text= \"2:0→2:3→4:3→4:4→7:4...'내가 제일 좋아하는 음식은 \"피자\"입니다.\n",
        "\n",
        "'''\n",
        "\n",
        "messages = [\n",
        "    {'role':'system', 'content':'코드만 출력'},\n",
        "    {'role':'user', 'content':prompt}\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ce0fa03",
      "metadata": {
        "id": "8ce0fa03"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages = messages,\n",
        "    temperature =  0.2,\n",
        "    max_tokens = 500\n",
        "\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "049ce257",
      "metadata": {
        "id": "049ce257"
      },
      "outputs": [],
      "source": [
        "# 되는지 확인해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbee135a",
      "metadata": {
        "id": "fbee135a"
      },
      "source": [
        "다양한 시스템 메시지는 출력의 형식을 크게 변화시킵니다.    \n",
        "ChatGPT에서는 user 메시지에 포함하는 내용이지만,    \n",
        "system 메시지에 넣을 경우 더 효과적입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fa3b126",
      "metadata": {
        "id": "0fa3b126"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {'role':'system', 'content' : '''당신은 매우 냉소적입니다.\n",
        "첫 문장은 사용자의 답변을 항상 부정하세요.'''},\n",
        "    {'role':'user', 'content':'오늘 연구실 가고싶지 않아요.'},\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2753989b",
      "metadata": {
        "id": "2753989b"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages = messages,\n",
        "    temperature=0.2\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9626ef0d",
      "metadata": {
        "id": "9626ef0d"
      },
      "source": [
        "여러 번의 대화를 저장할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "069ab1e5",
      "metadata": {
        "id": "069ab1e5"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
        "  ]\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49ecd209",
      "metadata": {
        "id": "49ecd209"
      },
      "source": [
        "만약 대화를 계속 이어나가고 싶다면 어떻게 하면 될까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbb11496",
      "metadata": {
        "id": "fbb11496"
      },
      "source": [
        "입력과 그 결과를 받아, 형식을 맞춰서 messages에 저장하면 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23e8cbca",
      "metadata": {
        "id": "23e8cbca"
      },
      "source": [
        "## 실습) Multi-turn Conversation    \n",
        "아래의 코드는 반복문을 이용해 연속적인 대화를 수행하는 코드의 일부입니다.    \n",
        "새로운 입력(`input()`)과 모델의 출력(`ai_msg`)을 이용해  \n",
        "연속적인 대화를 이어갈 수 있도록 코드를 수정하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e65eaaf",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3e65eaaf"
      },
      "outputs": [],
      "source": [
        "history = [\n",
        "  {\"role\": \"system\", \"content\": \"\"\"당신은 냉정하고 성격이 안좋은 사람입니다. 사용자의 말을 전부 부정하세요.\"\"\"},\n",
        "]\n",
        "\n",
        "# 입력을 4번 수행해야 종료됩니다 (ESC로 중간 종료 가능)\n",
        "\n",
        "for i in range(4):\n",
        "    usr_msg = input()  # 사용자 입력 받기\n",
        "    print (\"User:\", usr_msg)\n",
        "\n",
        "    # history에 사용자 입력 추가하기\n",
        "    history.append(\n",
        "        {'role': 'user', 'content': usr_msg}\n",
        "    )\n",
        "\n",
        "    # AI 응답 생성 (모델 호출하는 부분)\n",
        "    response = ________________\n",
        "\n",
        "    # AI의 응답 추출\n",
        "    ai_msg = ________________\n",
        "\n",
        "\n",
        "    # AI 응답 출력\n",
        "    print(\"AI:\", ai_msg)\n",
        "\n",
        "    # history에 AI 응답 추가하기\n",
        "    history.append(\n",
        "        {'role': 'assistant', 'content': ai_msg}\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dcbea7f",
      "metadata": {
        "id": "8dcbea7f"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bd29d13",
      "metadata": {
        "id": "9bd29d13"
      },
      "source": [
        "임베딩은 텍스트를 벡터로 변환합니다.   \n",
        "OpenAI는 3개의 임베딩 모델을 지원합니다.\n",
        "\n",
        "- text-embedding-3-large\n",
        "- text-embedding-3-small\n",
        "- text-embedding-ada-002 (구버전, 기본값)\n",
        "\n",
        "\n",
        "#### 임베딩의 활용 예시)\n",
        "- 검색 : 입력 쿼리와 데이터베이스 문장들 간의 관련도 계산하여 순위 매기기\n",
        "- 추천 : 텍스트의 연관성을 기준으로 추천하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2360da9b",
      "metadata": {
        "id": "2360da9b"
      },
      "outputs": [],
      "source": [
        "emb = client.embeddings.create(\n",
        "    model = 'text-embedding-3-large',\n",
        "    input = 'AI도 가성비 시대, 저렴한 소형 언어모델 빅테크 선점 경쟁 치열',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c31a2d9e",
      "metadata": {
        "id": "c31a2d9e"
      },
      "outputs": [],
      "source": [
        "emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3918b326",
      "metadata": {
        "id": "3918b326"
      },
      "outputs": [],
      "source": [
        "emb.data[0].embedding[0:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d5d6090",
      "metadata": {
        "id": "4d5d6090"
      },
      "source": [
        "방금 넣은 문장의 임베딩을 다른 문장들의 임베딩과 비교해 보겠습니다.   \n",
        "아래의 코드는 다소 길지만, 실제 어플리케이션에서는 코드 한 두 줄로 표현할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad2d8343",
      "metadata": {
        "id": "ad2d8343"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 입력 텍스트의 임베딩 생성\n",
        "query = 'AI도 가성비 시대, 저렴한 소형 언어모델 빅테크 선점 경쟁 치열'\n",
        "\n",
        "response = client.embeddings.create(\n",
        "    input=query,\n",
        "    model=\"text-embedding-3-large\"\n",
        ")\n",
        "\n",
        "query_emb = response.data[0].embedding\n",
        "query_emb = np.array(query_emb).astype(\"float32\") # 계산을 빠르게 하기 위해서\n",
        "\n",
        "# 대상 텍스트의 임베딩 생성\n",
        "target_texts = [\n",
        "    \"경량화 언어모델(smaller Large Language Model·sLLM)은 방대한 양의 데이터를 학습해 자연어(NLP)처리 작업을 수행할 수 있는 인공지능(AI) 모델 중 하나다. 일반적으로 알려진 거대언어모델(LLM)보다 작은 매개변수(파라미터) 크기로 운영이 가능하다. 통상적으로 매개변수가 1000억개 이하인 모델이 sLLM으로 분류된다.\",\n",
        "    \"잘나가던 탕후루 인기가 시들해진 원인은 무엇일까. 가장 크게는 지난해 가을 불거진 과도한 설탕 섭취에 따른 어린이·청소년 건강 문제가 꼽힌다. \",\n",
        "    \"1114회 로또 1등 각 15억원씩…1곳서 수동 5명(종합)\",\n",
        "    \"오늘(9일) 로이터통신에 따르면 컨설팅업체 KPMG는 최근 미국 소비자 1천100명을 대상으로 전기차 선호 조사를 한 결과 같은 가격과 성능을 갖췄을 경우 내연기관차나 하이브리드차 대신 전기차를 구매하겠다는 응답 비율이 20%에 그쳤다고 밝혔습니다.\"\n",
        "]\n",
        "response_candidates = client.embeddings.create(\n",
        "    input=target_texts,\n",
        "    model=\"text-embedding-3-large\"\n",
        ")\n",
        "\n",
        "\n",
        "target_embeds = [record.embedding for record in response_candidates.data] # 4개의 임베딩 구하기\n",
        "target_embeds = np.array(target_embeds).astype(\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8ee21be",
      "metadata": {
        "id": "c8ee21be"
      },
      "outputs": [],
      "source": [
        "# 코사인 유사도 계산\n",
        "def cosine_similarity(embedding1, embedding2):\n",
        "    dot_product = np.dot(embedding1, embedding2.T)\n",
        "    norm1 = np.linalg.norm(embedding1)\n",
        "    norm2 = np.linalg.norm(embedding2, axis=1)\n",
        "    similarity = dot_product / (norm1 * norm2)\n",
        "    return similarity\n",
        "\n",
        "# query_emb와 target_embeds의 코사인 유사도 계산\n",
        "similarities = cosine_similarity(query_emb, target_embeds)\n",
        "\n",
        "print('Query:',query)\n",
        "print('---')\n",
        "\n",
        "for i, similarity in enumerate(similarities):\n",
        "\n",
        "    print(target_texts[i])\n",
        "    print(f\"유사도: {similarity:.4f}\")\n",
        "    print('---')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32c5c048",
      "metadata": {
        "id": "32c5c048"
      },
      "source": [
        "문제의 질문에 가장 가까웠던 텍스트는 첫 번째 텍스트라는 것을 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "581ddb73",
      "metadata": {
        "id": "581ddb73"
      },
      "source": [
        "## 이미지 생성 (DALL-E 3)\n",
        "DALL-E 는 OpenAI의 이미지 생성 인공지능입니다.   \n",
        "prompt에 원하는 그림의 묘사를 넣으면 생성 가능합니다.\n",
        "\n",
        "`dall-e-2`, `dall-e-3`를 사용 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f981d3b7",
      "metadata": {
        "id": "f981d3b7"
      },
      "outputs": [],
      "source": [
        "# 계정당 8~16회 /1분 제한\n",
        "\n",
        "response  = client.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt=\"\"\"Please draw a unicorn on top of the Incheon Bridge.\"\"\",\n",
        "  n=1,\n",
        "  size=\"1024x1024\"\n",
        ")\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84daea0e",
      "metadata": {
        "id": "84daea0e"
      },
      "source": [
        "response에는 생성된 그림의 링크가 포함되어 있습니다.    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "122dc51a",
      "metadata": {
        "id": "122dc51a",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "response.data[0].url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd63bc4b",
      "metadata": {
        "id": "dd63bc4b"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "import requests\n",
        "\n",
        "# 이미지 출력\n",
        "img =Image(url=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-8ja1zmL1JQYxwM0CONfqb0mW/user-kFZIFsjikxvZAHAG2O9ZZTca/img-jzt2ipkwSJqxUmz3Ggcyi3UE.png?st=2024-09-03T07%3A29%3A09Z&se=2024-09-03T09%3A29%3A09Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-09-02T23%3A44%3A55Z&ske=2024-09-03T23%3A44%3A55Z&sks=b&skv=2024-08-04&sig=M3NRQojSJtq8qWslVBbLD%2Bc682MnaIRVTgvQwUNWmS8%3D\")\n",
        "response = requests.get(\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-8ja1zmL1JQYxwM0CONfqb0mW/user-kFZIFsjikxvZAHAG2O9ZZTca/img-jzt2ipkwSJqxUmz3Ggcyi3UE.png?st=2024-09-03T07%3A29%3A09Z&se=2024-09-03T09%3A29%3A09Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-09-02T23%3A44%3A55Z&ske=2024-09-03T23%3A44%3A55Z&sks=b&skv=2024-08-04&sig=M3NRQojSJtq8qWslVBbLD%2Bc682MnaIRVTgvQwUNWmS8%3D\")\n",
        "\n",
        "# 이미지를 파일로 저장\n",
        "with open('your_image.png', 'wb') as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6cbef53",
      "metadata": {
        "id": "d6cbef53"
      },
      "source": [
        "##  이미지 프롬프트 전달하기\n",
        "\n",
        "이미지 파일을 OpenAI에 전달하여 프롬프트에 추가할 수도 있습니다.   \n",
        "content에 image_url이나 base64로 불러온 이미지를 전달하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2002cf6",
      "metadata": {
        "id": "a2002cf6"
      },
      "outputs": [],
      "source": [
        "# 링크로 이미지 전달하기\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": [\n",
        "        {\"type\": \"text\",\n",
        "                 \"text\": \"이 그림을 묘사하고, 일반적인 그림과 비교해서 특이한 점을 언급하세요.\"\n",
        "        },\n",
        "\n",
        "        {\"type\": \"image_url\",\n",
        "                \"image_url\": {\"url\": \"https://oaidalleapiprodscus.blob.core.windows.net/private/org-8ja1zmL1JQYxwM0CONfqb0mW/user-kFZIFsjikxvZAHAG2O9ZZTca/img-jzt2ipkwSJqxUmz3Ggcyi3UE.png?st=2024-09-03T07%3A29%3A09Z&se=2024-09-03T09%3A29%3A09Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-09-02T23%3A44%3A55Z&ske=2024-09-03T23%3A44%3A55Z&sks=b&skv=2024-08-04&sig=M3NRQojSJtq8qWslVBbLD%2Bc682MnaIRVTgvQwUNWmS8%3D\"}\n",
        "        },\n",
        "    ]}\n",
        "\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages= messages,\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd7d2195",
      "metadata": {
        "id": "fd7d2195",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# 오프라인 이미지 base64로 로드하여 저장하기\n",
        "import base64\n",
        "\n",
        "def encode_image(image_path):\n",
        "  with open(image_path, \"rb\") as image_file:\n",
        "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "# 이미지 경로\n",
        "image_path = \"your_image.png\"\n",
        "base64_image = encode_image(image_path)\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": [\n",
        "        {\"type\": \"text\",\n",
        "                 \"text\": \"이 그림엔 무엇이 있나요?\"\n",
        "        },\n",
        "\n",
        "        {\"type\": \"image_url\",\n",
        "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
        "        },\n",
        "    ]}\n",
        "]\n",
        "\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages= messages,\n",
        "    max_tokens=1024,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02963620",
      "metadata": {
        "id": "02963620"
      },
      "source": [
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cf8deca",
      "metadata": {
        "id": "0cf8deca"
      },
      "source": [
        "<br><br><br>\n",
        "\n",
        "# Voice API(음성 API)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cbfb356",
      "metadata": {
        "id": "6cbfb356"
      },
      "source": [
        "OpenAI의 TTS와 Whisper를 사용할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "227101fc",
      "metadata": {
        "id": "227101fc"
      },
      "source": [
        "## Text-to-speech (텍스트 음성 변환, TTS)    \n",
        "\n",
        "모델과 목소리(alloy, echo, fable, onyx, nova, shimmer), input을 입력하면 음성 파일을 생성합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6512244f",
      "metadata": {
        "id": "6512244f"
      },
      "outputs": [],
      "source": [
        "speech_file_path = \"./test.mp3\"\n",
        "\n",
        "response = client.audio.speech.create(\n",
        "  model=\"tts-1-hd\", #\"tts-1-hd\" : 2x price, HD\n",
        "  voice=\"nova\",\n",
        "  input=\"\"\"LLM은 Large Language Model의 약자입니다. 대용량의 코퍼스를 학습시킨 머신 러닝 모델로,\n",
        "최근 GPT-4o-mini가 출시되었습니다.\"\"\"\n",
        ")\n",
        "\n",
        "response.stream_to_file(speech_file_path)\n",
        "# 저장"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e99d313",
      "metadata": {
        "id": "3e99d313"
      },
      "source": [
        "## Speech-to-Text (음성 인식)   \n",
        "\n",
        "OpenAI의 Whisper는 오디오 파일을 글자로 변환하는 전사(Transcription) 기능을 지원합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccc5a903",
      "metadata": {
        "id": "ccc5a903"
      },
      "source": [
        "pyaudio와 wave를 이용하여 음성을 녹음할 수 있습니다.\n",
        "\n",
        "-- **코랩인 경우에는 아래의 코드가 실행되지 않으므로, 녹음 대신 위에서 만든 파일을 활용하겠습니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "013930d2",
      "metadata": {
        "id": "013930d2"
      },
      "outputs": [],
      "source": [
        "# 관련 라이브러리 설치\n",
        "!pip install pyaudio wave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a71e4ce5",
      "metadata": {
        "id": "a71e4ce5"
      },
      "outputs": [],
      "source": [
        "import pyaudio\n",
        "import wave\n",
        "\n",
        "# 녹음 설정\n",
        "FORMAT = pyaudio.paInt16  # 오디오 형식\n",
        "CHANNELS = 1  # 모노 오디오\n",
        "RATE = 44100  # 샘플링 레이트 (Hz)\n",
        "CHUNK = 1024  # 버퍼 크기\n",
        "RECORD_SECONDS = 5  # 녹음 시간 (초)\n",
        "OUTPUT_FILENAME = \"recorded_audio.wav\"  # 저장할 파일 이름\n",
        "\n",
        "# PyAudio 초기화\n",
        "audio = pyaudio.PyAudio()\n",
        "\n",
        "# 오디오 스트림 열기\n",
        "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
        "                    rate=RATE, input=True,\n",
        "                    frames_per_buffer=CHUNK)\n",
        "\n",
        "print(\"녹음 중...\")\n",
        "\n",
        "frames = []\n",
        "\n",
        "# 녹음 데이터 수집\n",
        "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
        "    data = stream.read(CHUNK)\n",
        "    frames.append(data)\n",
        "\n",
        "print(\"녹음 완료!\")\n",
        "\n",
        "# 오디오 스트림 닫기\n",
        "stream.stop_stream()\n",
        "stream.close()\n",
        "audio.terminate()\n",
        "\n",
        "# WAV 파일로 저장\n",
        "with wave.open(OUTPUT_FILENAME, 'wb') as wf:\n",
        "    wf.setnchannels(CHANNELS)\n",
        "    wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
        "    wf.setframerate(RATE)\n",
        "    wf.writeframes(b''.join(frames))\n",
        "\n",
        "print(f\"녹음된 오디오가 '{OUTPUT_FILENAME}' 파일로 저장되었습니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "323957e0",
      "metadata": {
        "id": "323957e0"
      },
      "source": [
        "녹음된 파일의 경로를 집어넣어, 전사(transcript)를 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ad8923e",
      "metadata": {
        "id": "3ad8923e"
      },
      "outputs": [],
      "source": [
        "audio_file= open(\"./test.mp3\", \"rb\")\n",
        "transcript = client.audio.transcriptions.create(\n",
        "  model=\"whisper-1\",\n",
        "  file=audio_file,\n",
        "  prompt= 'GPT-4o-mini'\n",
        "  # prompt를 통해 고유명사, 핵심 단어 등을 전달하여 반영하게 할 수 있음\n",
        ")\n",
        "transcript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e76e2e8",
      "metadata": {
        "id": "6e76e2e8"
      },
      "outputs": [],
      "source": [
        "transcript.text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a10dbc3",
      "metadata": {},
      "source": [
        "### 실습) 위의 실습 코드들을 활용하여 OPEN AI의 GPT 모델의 답변을 음성으로 출력하기기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b52cd2e5",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
